{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "So4p6HSJ-yTg",
        "outputId": "869deb28-1245-48ec-d5b8-d73e757421b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFgsT-C9-3hE",
        "outputId": "dd732459-2c12-4112-e297-d60136abea1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.7/dist-packages (0.10.2)\n",
            "Requirement already satisfied: fiona>=1.8 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.8.20)\n",
            "Requirement already satisfied: pyproj>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from geopandas) (3.2.1)\n",
            "Requirement already satisfied: shapely>=1.6 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.8.0)\n",
            "Requirement already satisfied: pandas>=0.25.0 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.1.5)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (2.5.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (2021.10.8)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (1.1.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (0.7.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (57.4.0)\n",
            "Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (21.2.0)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (7.1.2)\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (1.19.5)\n"
          ]
        }
      ],
      "source": [
        "!cp /content/drive/MyDrive/sberbank/utils.py .\n",
        "!pip install geopandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UlxFXC4-419",
        "outputId": "82356ca3-0562-42a2-e282-b1d4339ee58b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir data\n",
        "!cp -r /content/drive/MyDrive/sberbank/. data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "2TDIoXTN-wtp"
      },
      "outputs": [],
      "source": [
        "from utils import *\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.metrics import mean_squared_log_error, mean_absolute_error, mean_squared_error\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.ensemble import AdaBoostRegressor, RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import lightgbm as lgb\n",
        "from xgboost import XGBRegressor, DMatrix, cv\n",
        "from xgboost import train as train_xgb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70sx-8YD-wtx"
      },
      "source": [
        "## Data description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgqwWeGS-wtz",
        "outputId": "7ce4db16-583d-40af-afa9-a00f6aebc45c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fix:  550\n",
            "Fix:  149\n"
          ]
        }
      ],
      "source": [
        "macro_df = pd.read_csv('data/macro.csv', parse_dates=['timestamp'])\n",
        "train_df = pd.read_csv('data/train.csv', index_col='id', parse_dates=['timestamp'])\n",
        "test_df = pd.read_csv('data/test.csv', index_col='id', parse_dates=['timestamp'])\n",
        "tverskoe_issue_fix(train_df)\n",
        "tverskoe_issue_fix(test_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XMfRzcU-wt2"
      },
      "source": [
        "## 1. Data preprocessing\n",
        "## I part (encoding and correcting mistakes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlOmdlGc-wt4"
      },
      "source": [
        "### Macro dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a1-RKD2-wt4",
        "outputId": "364f5c9a-8412-44e4-8716-0bb10c3dd98d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OK\n"
          ]
        }
      ],
      "source": [
        "macro_df['child_on_acc_pre_school'] = macro_df['child_on_acc_pre_school'].str.replace('#!', 'nan')\n",
        "for column in macro_df.select_dtypes('object').columns:\n",
        "    macro_df[column] = macro_df[column].str.replace(',', '.')\n",
        "    macro_df[column] = macro_df[column].astype(float)\n",
        "\n",
        "if not len(macro_df.select_dtypes('object').columns):\n",
        "    print('OK')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hOdB2O2-wt5"
      },
      "source": [
        "### Train dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "cefhW3sO-wt5"
      },
      "outputs": [],
      "source": [
        "train_df = encode(train_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSRp5y_C-wt7"
      },
      "source": [
        "### Test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "IMeNQ_Ad-wt8"
      },
      "outputs": [],
      "source": [
        "test_df = encode(test_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcRHlWsU-wt-"
      },
      "source": [
        "## II part (Filling missing values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8kHIiU0-wt_"
      },
      "source": [
        "XGBRegressor model handles `np.NaN` values itself"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfLaI5aH-wt_"
      },
      "source": [
        "## 2. Encoding `sub_area` feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "Yv6Ps6C9-wuA"
      },
      "outputs": [],
      "source": [
        "train_df['is_train'] = 1\n",
        "test_df['is_train'] = 0\n",
        "\n",
        "coords_df = pd.read_csv('data/coords.csv', index_col='id')\n",
        "all_df = pd.concat([train_df, test_df])\n",
        "\n",
        "all_df['latitude'] = coords_df['latitude']\n",
        "all_df['longitude'] = coords_df['longitude']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ad9TaN9Q-wuB"
      },
      "source": [
        "## 3. Removing outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "GS7abrdJ-wuB"
      },
      "outputs": [],
      "source": [
        "all_df = remove_outliers(all_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Y7doThf-wuB"
      },
      "source": [
        "## 4. Feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "HEFaFZFI-wuC"
      },
      "outputs": [],
      "source": [
        "all_df = create_new_features(all_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLOjaYTj-wuD"
      },
      "source": [
        "## 5. Removing fake prices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "2gVmPZwh-wuE"
      },
      "outputs": [],
      "source": [
        "train_df = all_df[all_df['is_train'] == 1].drop(['is_train'], axis=1)\n",
        "test_df = all_df[all_df['is_train'] == 0].drop(['is_train', 'price_doc'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "r2iMQl-I-wuE"
      },
      "outputs": [],
      "source": [
        "# train_df = remove_fake_prices(train_df)\n",
        "idx_outliers = np.loadtxt('data/idx_outliers.txt').astype(int)\n",
        "train_df = train_df.drop(idx_outliers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Z1VhzPO-wuF"
      },
      "source": [
        "### `Ensembling`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "kfljzjWx-wuF"
      },
      "outputs": [],
      "source": [
        "class my_LGBRegressor(object):\n",
        "    def __init__(self, params):\n",
        "        self.params = params\n",
        "\n",
        "    def fit(self, X, y, w=None):\n",
        "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)  # random_state=42\n",
        "        # x_train, y_train, w_train, x_valid, y_valid,  w_valid = X[train_id], y[train_id], w[train_id], X[test_id], y[test_id], w[test_id],\n",
        "        d_train = lgb.Dataset(X_train, y_train)  # weight=w_train\n",
        "        d_valid = lgb.Dataset(X_val, y_val)  # weight=w_val\n",
        "\n",
        "        bst_partial = lgb.train(self.params,\n",
        "                                d_train, 10000,\n",
        "                                valid_sets=d_valid,\n",
        "                                callbacks = [lgb.early_stopping(50)],\n",
        "                                verbose_eval=False)\n",
        "                                \n",
        "        num_round = bst_partial.best_iteration\n",
        "        d_all = lgb.Dataset(X, label=y)  # weight=w\n",
        "        self.bst = lgb.train(self.params, d_all, num_round, verbose_eval=False)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.bst.predict(X)\n",
        "\n",
        "\n",
        "class my_XGBRegressor(object):\n",
        "    def __init__(self, params, product_type=-1):\n",
        "        self.params = params\n",
        "        self.product_type = product_type\n",
        "\n",
        "    def fit(self, X, y, w=None):\n",
        "        # if w == None:\n",
        "        #    w = np.ones(X.shape[0])\n",
        "\n",
        "        if self.product_type == 0:\n",
        "            X = train_df[train_df['product_type'] == 0].drop(['sub_area', 'price_doc'], axis=1).values\n",
        "            y = np.log1p(test_df[test_df['product_type'] == 0]['price_doc'].values)\n",
        "            print(X.shape)\n",
        "\n",
        "        if self.product_type == 1:\n",
        "            X = train_df[train_df['product_type'] == 1].drop(['sub_area', 'price_doc'], axis=1).values\n",
        "            y = np.log1p(test_df[test_df['product_type'] == 1]['price_doc'].values)\n",
        "            print(X.shape)\n",
        "            \n",
        "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)  # random_state=42\n",
        "        d_train = DMatrix(X_train, label=y_train)  # weight = w_train\n",
        "        d_valid = DMatrix(X_val, label=y_val)  # weight = w_valid\n",
        "\n",
        "        print(f\"Training until validation scores don't improve for 50 rounds\") # !!!\n",
        "        if self.params['booster'] == 'gblinear':\n",
        "            num_boost_round = 10000\n",
        "        else:\n",
        "            num_boost_round = 5000\n",
        "\n",
        "        bst_partial = train_xgb(self.params,\n",
        "                                d_train,\n",
        "                                num_boost_round=num_boost_round,\n",
        "                                early_stopping_rounds=50,\n",
        "                                evals=[(d_train, 'train'), (d_valid, 'val')],\n",
        "                                verbose_eval=500)\n",
        "\n",
        "        last_round = bst_partial.best_iteration\n",
        "        print(f\"[{last_round}]  RMSE: {bst_partial.best_score}\")\n",
        "\n",
        "        d_all = DMatrix(X, label=y)  # weight = w\n",
        "        self.bst = train_xgb(self.params,\n",
        "                             d_all,\n",
        "                             num_boost_round=last_round,\n",
        "                             evals=[(d_train, 'train')],\n",
        "                             verbose_eval=500)\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        d_test = DMatrix(X_test)\n",
        "        return self.bst.predict(d_test)\n",
        "\n",
        "\n",
        "class Ensemble(object):\n",
        "    def __init__(self, n_folds, stacker, base_models):\n",
        "        self.n_folds = n_folds\n",
        "        self.stacker = stacker\n",
        "        self.base_models = base_models\n",
        "\n",
        "    def fit_predict(self, train_df, test_df):\n",
        "        X = train_df.drop(['sub_area', 'price_doc'], axis=1).values\n",
        "        y = np.log1p(train_df['price_doc']).values\n",
        "        # w = train_df['w'].values\n",
        "        X_test = test_df.drop('sub_area', axis=1).values\n",
        "\n",
        "        all_df = pd.concat([train_df.drop(['sub_area', 'price_doc'], axis=1), test_df.drop('sub_area', axis=1)])\n",
        "        imputer = SimpleImputer(strategy='median') # mean\n",
        "        imputer.fit(all_df)\n",
        "\n",
        "        kf = KFold(n_splits=self.n_folds, shuffle=True)  # random_state=42\n",
        "        folds = list(kf.split(X, y))\n",
        "\n",
        "        S_train = np.zeros((X.shape[0], len(self.base_models)))\n",
        "        S_test = np.zeros((X_test.shape[0], len(self.base_models)))\n",
        "\n",
        "        for i, model in enumerate(self.base_models):\n",
        "            print('\\n\\nTraining model: ' + str(type(model).__name__))\n",
        "            S_test_i = np.zeros((X_test.shape[0], len(folds)))\n",
        "\n",
        "            for j, (train_idx, test_idx) in enumerate(folds):\n",
        "                print('ROUND ' + str(j+1))\n",
        "\n",
        "                if (not isinstance(model, my_XGBRegressor)) and (not isinstance(model, my_LGBRegressor)):\n",
        "                    X = imputer.transform(X)\n",
        "                    X_test = imputer.transform(X_test)\n",
        "\n",
        "                X_train = X[train_idx]\n",
        "                y_train = y[train_idx]\n",
        "                # w_train = w[train_idx]\n",
        "                X_holdout = X[test_idx]\n",
        "                y_holdout = y[test_idx]\n",
        "\n",
        "                model.fit(X_train, y_train)  # w_train\n",
        "\n",
        "                y_train_pred = model.predict(X_train)\n",
        "                y_pred = model.predict(X_holdout)\n",
        "\n",
        "                print(f\"[ALL]  train-RMSE  : {mean_squared_error(y_train_pred, y_train, squared=False)}\")\n",
        "                print(f\"[ALL]  holdout-RMSE: {mean_squared_error(y_pred, y_holdout, squared=False)}\")\n",
        "\n",
        "                S_train[test_idx, i] = y_pred\n",
        "                S_test_i[:, j] = model.predict(X_test)\n",
        "\n",
        "            S_test[:, i] = S_test_i.mean(axis=1)\n",
        "\n",
        "        self.S_train, self.S_test, self.y = S_train, S_test, y\n",
        "        self.stacker.fit(S_train, y)\n",
        "        y_pred = self.stacker.predict(S_test)\n",
        "        y_pred_train = self.stacker.predict(S_train)\n",
        "        print(f\"\\n\\n[THE END]  train-RMSE  : {mean_squared_error(y_pred_train, y, squared=False)}\")\n",
        "\n",
        "        return y_pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "B3QSIrz0-wuH"
      },
      "outputs": [],
      "source": [
        "params_xgb_tree = {'objective': 'reg:squarederror',\n",
        "                   'booster': 'gbtree',\n",
        "                   'tree_method': 'gpu_hist',\n",
        "                   'base_score': 7,\n",
        "                   'learning_rate': 0.05,\n",
        "                   'max_depth': 4,\n",
        "                   'min_child_weight': 7,\n",
        "                   'subsample': 1,\n",
        "                   'colsample_bytree': 0.9,\n",
        "                   'reg_lambda': 5,\n",
        "                   'reg_alpha': 1,\n",
        "                   'eval_metric': 'rmse',\n",
        "                   'seed': 42,\n",
        "                   'nthread': -1\n",
        "                   }\n",
        "\n",
        "\n",
        "params_xgb_lin = {'objective': 'reg:squarederror',\n",
        "                  'booster': 'gblinear',\n",
        "                  'tree_method': 'gpu_hist',\n",
        "                  'base_score': 7,\n",
        "                  'learning_rate': 1,\n",
        "                  'eval_metric': 'rmse',\n",
        "                  'seed': 42,\n",
        "                  'nthread': -1\n",
        "                  }\n",
        "\n",
        "params_lgb = {'objective': 'regression', \n",
        "              'metric': 'rmse',\n",
        "              'learning_rate': 0.05, \n",
        "              'max_depth': -1, \n",
        "              'sub_feature': 0.7, \n",
        "              'sub_row': 0.9,\n",
        "              'num_leaves': 15, \n",
        "              'min_data': 30, \n",
        "              'max_bin': 20,\n",
        "              'bagging_freq': 40,\n",
        "              'force_col_wise': True,\n",
        "              'verbosity': 0}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCAoOMeV-wuH",
        "outputId": "9e63a9b9-7d5f-40d2-c3c3-1a7a08a1ab20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Training model: my_LGBRegressor\n",
            "ROUND 1\n",
            "Training until validation scores don't improve for 50 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[710]\tvalid_0's rmse: 0.145456\n",
            "[ALL]  train-RMSE  : 0.09754595509043086\n",
            "[ALL]  holdout-RMSE: 0.13952376998080132\n",
            "ROUND 2\n",
            "Training until validation scores don't improve for 50 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[638]\tvalid_0's rmse: 0.1339\n",
            "[ALL]  train-RMSE  : 0.10099173395892287\n",
            "[ALL]  holdout-RMSE: 0.13678378715893455\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "[0]\ttrain-rmse:0.445805\tval-rmse:0.449953\n",
            "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
            "\n",
            "Will train until val-rmse hasn't improved in 50 rounds.\n",
            "[500]\ttrain-rmse:0.325829\tval-rmse:0.329471\n",
            "[1000]\ttrain-rmse:0.247508\tval-rmse:0.250838\n",
            "[1500]\ttrain-rmse:0.198697\tval-rmse:0.201815\n",
            "[2000]\ttrain-rmse:0.170047\tval-rmse:0.172991\n",
            "[2500]\ttrain-rmse:0.154247\tval-rmse:0.157028\n",
            "[3000]\ttrain-rmse:0.145968\tval-rmse:0.148604\n",
            "[3500]\ttrain-rmse:0.141778\tval-rmse:0.144294\n",
            "[4000]\ttrain-rmse:0.139701\tval-rmse:0.142123\n",
            "[4500]\ttrain-rmse:0.138682\tval-rmse:0.141035\n",
            "[5000]\ttrain-rmse:0.138185\tval-rmse:0.140488\n",
            "[5500]\ttrain-rmse:0.137944\tval-rmse:0.14021\n",
            "[6000]\ttrain-rmse:0.137826\tval-rmse:0.140068\n",
            "[6500]\ttrain-rmse:0.137769\tval-rmse:0.139993\n",
            "[7000]\ttrain-rmse:0.137742\tval-rmse:0.139953\n",
            "[7500]\ttrain-rmse:0.137728\tval-rmse:0.13993\n",
            "[8000]\ttrain-rmse:0.137722\tval-rmse:0.139918\n",
            "Stopping. Best iteration:\n",
            "[7969]\ttrain-rmse:0.137722\tval-rmse:0.139918\n",
            "\n",
            "[7969]  RMSE: 0.139918\n",
            "[0]\ttrain-rmse:0.445889\n",
            "[500]\ttrain-rmse:0.32561\n",
            "[1000]\ttrain-rmse:0.247172\n",
            "[1500]\ttrain-rmse:0.198355\n",
            "[2000]\ttrain-rmse:0.16976\n",
            "[2500]\ttrain-rmse:0.154031\n",
            "[3000]\ttrain-rmse:0.145818\n",
            "[3500]\ttrain-rmse:0.141678\n",
            "[4000]\ttrain-rmse:0.139635\n",
            "[4500]\ttrain-rmse:0.13864\n",
            "[5000]\ttrain-rmse:0.138158\n",
            "[5500]\ttrain-rmse:0.137927\n",
            "[6000]\ttrain-rmse:0.137816\n",
            "[6500]\ttrain-rmse:0.137763\n",
            "[7000]\ttrain-rmse:0.137738\n",
            "[7500]\ttrain-rmse:0.137727\n",
            "[7968]\ttrain-rmse:0.137722\n",
            "\n",
            "\n",
            "[THE END]  train-RMSE  : 0.13815813482197797\n"
          ]
        }
      ],
      "source": [
        "#stacker\n",
        "xgb_lin = my_XGBRegressor(params_xgb_lin)\n",
        "LR = LinearRegression()\n",
        "\n",
        "#base models\n",
        "xgb_tree = my_XGBRegressor(params_xgb_tree)\n",
        "\n",
        "xgb_tree_0 = my_XGBRegressor(params_xgb_tree, 0)\n",
        "xgb_tree_1 = my_XGBRegressor(params_xgb_tree, 1)\n",
        "\n",
        "lgb_tree = my_LGBRegressor(params_lgb)\n",
        "\n",
        "RF = RandomForestRegressor(n_estimators=500, max_depth=5, max_features=0.2, n_jobs=-1)\n",
        "ETR = ExtraTreesRegressor(n_estimators=500, max_depth=5, max_features=0.3, n_jobs=-1)\n",
        "Ada = AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=5), n_estimators=200)\n",
        "GBR = GradientBoostingRegressor(n_estimators=200, max_depth=5, max_features=0.5)\n",
        "\n",
        "E = Ensemble(\n",
        "    n_folds=2,\n",
        "    stacker=xgb_lin,\n",
        "    base_models=[lgb_tree] # -Ada? -GBR? +xgb_tree_0? +xgb_tree_1?\n",
        ")\n",
        "\n",
        "y_pred = E.fit_predict(train_df, test_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iQO2k2l-wuI"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "UE3unrr2-wuI"
      },
      "outputs": [],
      "source": [
        "submission = pd.read_csv('data/sample_submission.csv', index_col='id')\n",
        "result = np.expm1(y_pred)\n",
        "\n",
        "if len(result[result < 0]):\n",
        "    print('WARNING: NEGATIVE PREDICTIONS')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "cUD3MPsL-wuI"
      },
      "outputs": [],
      "source": [
        "submission['price_doc'] = result # 0.9\n",
        "submission.to_csv('data/submission.csv', index='id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swIVUL0G-wuJ"
      },
      "outputs": [],
      "source": [
        "# !kaggle competitions submit -c sberbank-russian-housing-market -f \"submits/submission.csv\" -m \"Ensemble\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c214Jxm9-wuJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "ensembling_2.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
