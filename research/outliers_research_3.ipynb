{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2TDIoXTN-wtp"
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import mean_squared_log_error, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import AdaBoostRegressor, RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import lightgbm as lgb\n",
    "from xgboost import XGBRegressor, DMatrix, cv\n",
    "from xgboost import train as train_xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70sx-8YD-wtx"
   },
   "source": [
    "## Data description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lgqwWeGS-wtz",
    "outputId": "7ce4db16-583d-40af-afa9-a00f6aebc45c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fix:  550\n",
      "Fix:  149\n"
     ]
    }
   ],
   "source": [
    "macro_df = pd.read_csv('data/macro.csv', parse_dates=['timestamp'])\n",
    "train_df = pd.read_csv('data/train.csv', index_col='id', parse_dates=['timestamp'])\n",
    "test_df = pd.read_csv('data/test.csv', index_col='id', parse_dates=['timestamp'])\n",
    "tverskoe_issue_fix(train_df)\n",
    "tverskoe_issue_fix(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6XMfRzcU-wt2"
   },
   "source": [
    "## 1. Data preprocessing\n",
    "## I part (encoding and correcting mistakes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WlOmdlGc-wt4"
   },
   "source": [
    "### Macro dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6a1-RKD2-wt4",
    "outputId": "364f5c9a-8412-44e4-8716-0bb10c3dd98d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "macro_df['child_on_acc_pre_school'] = macro_df['child_on_acc_pre_school'].str.replace('#!', 'nan')\n",
    "for column in macro_df.select_dtypes('object').columns:\n",
    "    macro_df[column] = macro_df[column].str.replace(',', '.')\n",
    "    macro_df[column] = macro_df[column].astype(float)\n",
    "\n",
    "if not len(macro_df.select_dtypes('object').columns):\n",
    "    print('OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5hOdB2O2-wt5"
   },
   "source": [
    "### Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "cefhW3sO-wt5"
   },
   "outputs": [],
   "source": [
    "train_df = encode(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vSRp5y_C-wt7"
   },
   "source": [
    "### Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "IMeNQ_Ad-wt8"
   },
   "outputs": [],
   "source": [
    "test_df = encode(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZcRHlWsU-wt-"
   },
   "source": [
    "## II part (Filling missing values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8kHIiU0-wt_"
   },
   "source": [
    "XGBRegressor model handles `np.NaN` values itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FfLaI5aH-wt_"
   },
   "source": [
    "## 2. Encoding `sub_area` feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Yv6Ps6C9-wuA"
   },
   "outputs": [],
   "source": [
    "train_df['is_train'] = 1\n",
    "test_df['is_train'] = 0\n",
    "\n",
    "coords_df = pd.read_csv('data/coords.csv', index_col='id')\n",
    "all_df = pd.concat([train_df, test_df])\n",
    "\n",
    "all_df['latitude'] = coords_df['latitude']\n",
    "all_df['longitude'] = coords_df['longitude']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ad9TaN9Q-wuB"
   },
   "source": [
    "## 3. Removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(all_df):\n",
    "    # Numerical outliers\n",
    "    all_df.loc[all_df['full_sq'] < 10, 'full_sq'] = np.nan\n",
    "    all_df.loc[all_df['full_sq'] > 1000, 'full_sq'] /= 100  # np.nan or /= 100\n",
    "\n",
    "    all_df.loc[(all_df[\"full_sq\"] > 250) &\n",
    "               (all_df[\"life_sq\"] / all_df[\"full_sq\"] < 0.3), 'full_sq'] /= 10  # np.nan or /= 10\n",
    "\n",
    "    all_df.loc[(all_df[\"full_sq\"] > 210) &\n",
    "               (all_df[\"price_doc\"] < 10_000_000) &\n",
    "               (all_df[\"life_sq\"] > 100), 'life_sq'] /= 10  # np.nan or /= 10\n",
    "    all_df.loc[(all_df[\"full_sq\"] > 210) & (all_df[\"price_doc\"] < 10_000_000), 'full_sq'] /= 10  # np.nan or /= 10\n",
    "\n",
    "    all_df.loc[all_df['life_sq'] < 5, 'life_sq'] = np.nan\n",
    "    all_df.loc[all_df['life_sq'] > 1000, 'life_sq'] /= 100  # 74/78 or /= 100\n",
    "    all_df.loc[(all_df['life_sq'] > 300) &\n",
    "               (all_df['life_sq'] == all_df['full_sq']*10), 'life_sq'] /= 10\n",
    "    all_df.loc[all_df['life_sq'] > 300, 'life_sq'] /= 10  # np.nan or /= 10\n",
    "\n",
    "    all_df.loc[13120, \"build_year\"] = all_df.loc[13120, \"kitch_sq\"]\n",
    "    all_df.loc[all_df['kitch_sq'] > 200, 'kitch_sq'] = np.nan\n",
    "    all_df.loc[all_df['kitch_sq'] < 2, 'kitch_sq'] = np.nan\n",
    "\n",
    "    all_df.loc[all_df['floor'] == 0, 'floor'] = np.nan\n",
    "    all_df.loc[all_df['floor'] == 77, 'floor'] = np.nan\n",
    "\n",
    "    all_df.loc[all_df['max_floor'] == 0, 'max_floor'] = np.nan\n",
    "    all_df.loc[all_df['max_floor'] > 57, 'max_floor'] = np.nan\n",
    "\n",
    "    all_df.loc[all_df['build_year'] == 2, 'build_year'] = 2014\n",
    "    all_df.loc[all_df['build_year'] == 20, 'build_year'] = 2014\n",
    "    all_df.loc[all_df['build_year'] == 215, 'build_year'] = 2015\n",
    "    all_df.loc[all_df['build_year'] == 1691, 'build_year'] = 1961\n",
    "    all_df.loc[all_df['build_year'] == 4965, 'build_year'] = 1965\n",
    "    all_df.loc[all_df['build_year'] == 20052009, 'build_year'] = 2009\n",
    "    all_df.loc[all_df['build_year'] < 1850, 'build_year'] = np.nan\n",
    "    all_df.loc[all_df['build_year'] > 2020, 'build_year'] = np.nan\n",
    "\n",
    "    all_df.loc[all_df['num_room'] == 0, 'num_room'] = np.nan\n",
    "    all_df.loc[all_df['num_room'] > 15, 'num_room'] = np.nan\n",
    "\n",
    "    all_df.loc[all_df['state'] > 30, 'state'] = np.nan\n",
    "\n",
    "    all_df.loc[all_df['preschool_quota'] == 0, 'preschool_quota'] = np.nan\n",
    "\n",
    "    # Logical outliers\n",
    "    all_df.loc[all_df['life_sq'] > all_df['full_sq'], 'life_sq'] = np.nan\n",
    "    all_df.loc[all_df['floor'] > all_df['max_floor'], 'max_floor'] = np.nan\n",
    "    all_df.loc[all_df['kitch_sq'] >= all_df['life_sq'], 'kitch_sq'] = np.nan\n",
    "\n",
    "    return all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "GS7abrdJ-wuB"
   },
   "outputs": [],
   "source": [
    "all_df = remove_outliers(all_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Y7doThf-wuB"
   },
   "source": [
    "## 4. Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "HEFaFZFI-wuC"
   },
   "outputs": [],
   "source": [
    "all_df = create_new_features(all_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VLOjaYTj-wuD"
   },
   "source": [
    "## 5. Removing fake prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOVED: 69\n"
     ]
    }
   ],
   "source": [
    "train_df = remove_fake_prices(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "2gVmPZwh-wuE"
   },
   "outputs": [],
   "source": [
    "train_df = all_df[all_df['is_train'] == 1].drop(['is_train'], axis=1)\n",
    "test_df = all_df[all_df['is_train'] == 0].drop(['is_train', 'price_doc'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `product_type == 'Investment'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_0 = train_df[train_df['product_type'] == 0]\n",
    "test_df_0 = test_df[test_df['product_type'] == 0]\n",
    "\n",
    "X = train_df_0.drop(['sub_area', 'price_doc'], axis=1).copy()\n",
    "y = np.log1p(train_df_0['price_doc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = DMatrix(X, label=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'objective': 'reg:squarederror',\n",
    "          'booster': 'gbtree',\n",
    "          'tree_method': 'gpu_hist',\n",
    "          'base_score': 7,\n",
    "          'learning_rate': 0.05,\n",
    "          'max_depth': 4,\n",
    "          'min_child_weight': 7,\n",
    "          'subsample': 1,\n",
    "          'colsample_bytree': 0.9,\n",
    "          'reg_lambda': 5,\n",
    "          'reg_alpha': 1,\n",
    "          'eval_metric': 'rmse',\n",
    "          'seed': 42,\n",
    "          'nthread': -1\n",
    "          }\n",
    "\n",
    "cv_results = cv(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=5000,\n",
    "    early_stopping_rounds=50,\n",
    "    nfold=5,\n",
    "    shuffle=True,\n",
    "    metrics={'rmse'},\n",
    "    verbose_eval=True,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
